{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Dummy-classifier\" data-toc-modified-id=\"Dummy-classifier-1\">Dummy classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Trying-separator-=-'\\n'\" data-toc-modified-id=\"Trying-separator-=-'\\n'-1.1\">Trying separator = '\\n'</a></span></li><li><span><a href=\"#Dummy-classifier-steps-(TF-IDF)\" data-toc-modified-id=\"Dummy-classifier-steps-(TF-IDF)-1.2\">Dummy classifier steps (TF-IDF)</a></span></li><li><span><a href=\"#Testing-our-model-on-the-test-dataset\" data-toc-modified-id=\"Testing-our-model-on-the-test-dataset-1.3\">Testing our model on the test dataset</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook would simply be to run a basic classifier on the non-preprocessed datasets. From the scripts given, we have a vocabulary (vocab.pkl) and the co-occurence matrix (cooc.pkl) and now we should simply compute an embedding vector for each tweet but I can't figure out how.\n",
    "\n",
    "\n",
    "\n",
    "Remarks : \n",
    "- The data sets are not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import open_by_tweets\n",
    "from utils import create_csv_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive tweets: 81651\n",
      "Number of negative tweets: 46323\n"
     ]
    }
   ],
   "source": [
    "train_pos = open_by_tweets('data/train_pos.txt')\n",
    "train_neg = open_by_tweets('data/train_neg.txt')\n",
    "print(\"Number of positive tweets:\",len(train_pos))\n",
    "print(\"Number of negative tweets:\",len(train_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame({'tweet' : train_pos[1::]}) #first entry was empty\n",
    "df_pos['label'] = 1 #label 1 for happy tweet\n",
    "df_neg = pd.DataFrame({'tweet' : train_neg})\n",
    "df_neg['label'] = 0\n",
    "df_tweets = df_pos.append(df_neg) #our labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dunno justin read my mention or not . only ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just put casper in a box ! \" looved the battl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thanks sir &gt; &gt; don't trip lil mama ... just k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yay ! ! #lifecompleted . tweet / facebook me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46318</th>\n",
       "      <td>.. its problem that you will never follow me ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46319</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46320</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46321</th>\n",
       "      <td>ofcos honey ! but i'm not meeting you .. imis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46322</th>\n",
       "      <td>darling i lost my internet connection .. and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127973 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  label\n",
       "0       i dunno justin read my mention or not . only ...      1\n",
       "1       just put casper in a box ! \" looved the battl...      1\n",
       "2                                                             1\n",
       "3       thanks sir > > don't trip lil mama ... just k...      1\n",
       "4       yay ! ! #lifecompleted . tweet / facebook me ...      1\n",
       "...                                                  ...    ...\n",
       "46318   .. its problem that you will never follow me ...      0\n",
       "46319                                                         0\n",
       "46320                                                         0\n",
       "46321   ofcos honey ! but i'm not meeting you .. imis...      0\n",
       "46322   darling i lost my internet connection .. and ...      0\n",
       "\n",
       "[127973 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying separator = '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_pos.txt',\"r\") as file:\n",
    "    train_pos = file.read().split('\\n')\n",
    "    \n",
    "with open('data/train_neg.txt',\"r\") as file:\n",
    "    train_neg = file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.DataFrame({'tweet' : train_pos}) #first entry was empty\n",
    "df_pos['label'] = 1 #label 1 for happy tweet\n",
    "df_neg = pd.DataFrame({'tweet' : train_neg})\n",
    "df_neg['label'] = 0\n",
    "df_tweets = df_pos.append(df_neg) #our labelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i dunno justin read my mention or not ....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>because your logic is so dumb , i won't even c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\" &lt;user&gt; just put casper in a box ! \" looved t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; thanks sir &gt; &gt; don't trip lil ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visiting my brother tmr is the bestest birthda...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>&lt;user&gt; darling i lost my internet connection ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>kanguru defender basic 4 gb usb 2.0 flash driv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>rizan is sad now</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>no text back ? yea , he mad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    tweet  label\n",
       "0       <user> i dunno justin read my mention or not ....      1\n",
       "1       because your logic is so dumb , i won't even c...      1\n",
       "2       \" <user> just put casper in a box ! \" looved t...      1\n",
       "3       <user> <user> thanks sir > > don't trip lil ma...      1\n",
       "4       visiting my brother tmr is the bestest birthda...      1\n",
       "...                                                   ...    ...\n",
       "99996   <user> darling i lost my internet connection ....      0\n",
       "99997   kanguru defender basic 4 gb usb 2.0 flash driv...      0\n",
       "99998                                    rizan is sad now      0\n",
       "99999                         no text back ? yea , he mad      0\n",
       "100000                                                         0\n",
       "\n",
       "[200002 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy classifier steps (TF-IDF)\n",
    "* Compute TF-IDF of the words\n",
    "* Build linear regression model \n",
    "* ???\n",
    "* Classify :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_tweets['tweet'], df_tweets['label'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(2, 3))\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150001, 1716971)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape\n",
    "#print(X_train_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00 00',\n",
       " '00 00 170412',\n",
       " '00 00 theatre',\n",
       " '00 01',\n",
       " '00 01 02',\n",
       " '00 04',\n",
       " '00 04 carbon',\n",
       " '00 06',\n",
       " '00 06 extreme',\n",
       " '00 06 in',\n",
       " '00 10',\n",
       " '00 10 designer',\n",
       " '00 10 jd',\n",
       " '00 115',\n",
       " '00 115 lbs',\n",
       " '00 12',\n",
       " '00 12 00',\n",
       " '00 164607',\n",
       " '00 164607 001',\n",
       " '00 170412',\n",
       " '00 170412 annisamaliaenhas',\n",
       " '00 20',\n",
       " '00 20 bore',\n",
       " '00 2012',\n",
       " '00 2012 04',\n",
       " '00 24',\n",
       " '00 24 00',\n",
       " '00 25',\n",
       " '00 25 in',\n",
       " '00 30',\n",
       " '00 30 parent',\n",
       " '00 3b',\n",
       " '00 3b freeware',\n",
       " '00 42',\n",
       " '00 42 00',\n",
       " '00 aerographic',\n",
       " '00 aerographic replica',\n",
       " '00 again',\n",
       " '00 again for',\n",
       " '00 am',\n",
       " '00 am 00',\n",
       " '00 am club',\n",
       " '00 am here',\n",
       " '00 am in',\n",
       " '00 am jeffery',\n",
       " '00 am uhhh',\n",
       " '00 am with',\n",
       " '00 amazing',\n",
       " '00 amazing url',\n",
       " '00 and',\n",
       " '00 and it',\n",
       " '00 and ting',\n",
       " '00 at',\n",
       " '00 at my',\n",
       " '00 at nite',\n",
       " '00 bar',\n",
       " '00 bar with',\n",
       " '00 be',\n",
       " '00 be there',\n",
       " '00 bid',\n",
       " '00 bid end',\n",
       " '00 bids',\n",
       " '00 bids end',\n",
       " '00 cigarette',\n",
       " '00 cigarette lighter',\n",
       " '00 city',\n",
       " '00 city select',\n",
       " '00 clear',\n",
       " '00 clear 11c',\n",
       " '00 cold',\n",
       " '00 cold air',\n",
       " '00 compatible',\n",
       " '00 compatible laptop',\n",
       " '00 cont',\n",
       " '00 cont url',\n",
       " '00 ct',\n",
       " '00 ct dazzling',\n",
       " '00 cttw',\n",
       " '00 cttw the',\n",
       " '00 customers',\n",
       " '00 customers also',\n",
       " '00 device',\n",
       " '00 device ios',\n",
       " '00 dia',\n",
       " '00 dia 15',\n",
       " '00 dia revolving',\n",
       " '00 expensive',\n",
       " '00 expensive going',\n",
       " '00 flat',\n",
       " '00 flat fee',\n",
       " '00 fleming',\n",
       " '00 fleming audio',\n",
       " '00 from',\n",
       " '00 from california',\n",
       " '00 from uk',\n",
       " '00 garmin',\n",
       " '00 garmin gps',\n",
       " '00 gauge',\n",
       " '00 gauge 10mm',\n",
       " '00 ghz',\n",
       " '00 ghz ir',\n",
       " '00 gift',\n",
       " '00 gift card',\n",
       " '00 gmt',\n",
       " '00 gmt following',\n",
       " '00 good',\n",
       " '00 good bye',\n",
       " '00 grip',\n",
       " '00 grip lg',\n",
       " '00 hammary',\n",
       " '00 hammary structure',\n",
       " '00 here',\n",
       " '00 here in',\n",
       " '00 hidden',\n",
       " '00 hidden mickeys',\n",
       " '00 hit',\n",
       " '00 hit ima',\n",
       " '00 honda',\n",
       " '00 honda civic',\n",
       " '00 in',\n",
       " '00 in free',\n",
       " '00 in january',\n",
       " '00 inch',\n",
       " '00 inch 00',\n",
       " '00 inch 1880',\n",
       " '00 infa',\n",
       " '00 infa equities',\n",
       " '00 item',\n",
       " '00 item 01010323',\n",
       " '00 lb',\n",
       " '00 lb pack',\n",
       " '00 lg',\n",
       " '00 lg elesa',\n",
       " '00 live',\n",
       " '00 live di',\n",
       " '00 love',\n",
       " '00 love you',\n",
       " '00 lucky',\n",
       " '00 lucky for',\n",
       " '00 mack',\n",
       " '00 mack camera',\n",
       " '00 makes',\n",
       " '00 makes me',\n",
       " '00 mbt',\n",
       " '00 mbt is',\n",
       " '00 mins',\n",
       " '00 mins url',\n",
       " '00 ml',\n",
       " '00 ml kills',\n",
       " '00 music',\n",
       " '00 music man',\n",
       " '00 nquery',\n",
       " '00 nquery is',\n",
       " '00 od',\n",
       " '00 od 90',\n",
       " '00 olympics',\n",
       " '00 olympics are',\n",
       " '00 ounce',\n",
       " '00 ounce pack',\n",
       " '00 per',\n",
       " '00 per annum',\n",
       " '00 per hour',\n",
       " '00 pm',\n",
       " '00 pm 11',\n",
       " '00 pm and',\n",
       " '00 pm fact',\n",
       " '00 pm follow',\n",
       " '00 pm free',\n",
       " '00 pm let',\n",
       " '00 pm missouri',\n",
       " '00 pm on',\n",
       " '00 pm see',\n",
       " '00 pm the',\n",
       " '00 pm till',\n",
       " '00 pm url',\n",
       " '00 pm2',\n",
       " '00 pm2 205',\n",
       " '00 price',\n",
       " '00 price target',\n",
       " '00 princess',\n",
       " '00 princess and',\n",
       " '00 protect',\n",
       " '00 protect your',\n",
       " '00 radius',\n",
       " '00 radius mandrel',\n",
       " '00 replacement',\n",
       " '00 replacement print',\n",
       " '00 review',\n",
       " '00 review url',\n",
       " '00 router',\n",
       " '00 router collet',\n",
       " '00 rpm',\n",
       " '00 rpm dba',\n",
       " '00 seamaster',\n",
       " '00 seamaster planet',\n",
       " '00 since',\n",
       " '00 since he',\n",
       " '00 small',\n",
       " '00 small sized',\n",
       " '00 so',\n",
       " '00 so boreddd',\n",
       " '00 so just',\n",
       " '00 somewhere',\n",
       " '00 somewhere right',\n",
       " '00 temp',\n",
       " '00 temp 18',\n",
       " '00 temp 19',\n",
       " '00 the',\n",
       " '00 the exhaust',\n",
       " '00 the knoxs',\n",
       " '00 theatre',\n",
       " '00 theatre train',\n",
       " '00 then',\n",
       " '00 then might',\n",
       " '00 this',\n",
       " '00 this week',\n",
       " '00 to',\n",
       " '00 to tell',\n",
       " '00 today',\n",
       " '00 today was',\n",
       " '00 tomorrow',\n",
       " '00 tomorrow to',\n",
       " '00 tonight',\n",
       " '00 url',\n",
       " '00 user',\n",
       " '00 user live',\n",
       " '00 utilizes',\n",
       " '00 utilizes the',\n",
       " '00 view',\n",
       " '00 view auction',\n",
       " '00 when',\n",
       " '00 when done',\n",
       " '00 wib',\n",
       " '00 wib aspac',\n",
       " '00 you',\n",
       " '00 you can',\n",
       " '00 you me',\n",
       " '000 000',\n",
       " '000 000 beliebers',\n",
       " '000 000 idevices',\n",
       " '000 000 jews',\n",
       " '000 000 more',\n",
       " '000 000 seats',\n",
       " '000 000 times',\n",
       " '000 000 views',\n",
       " '000 000 women',\n",
       " '000 110',\n",
       " '000 110 2390',\n",
       " '000 45',\n",
       " '000 45 down',\n",
       " '000 actually',\n",
       " '000 actually lowest',\n",
       " '000 and',\n",
       " '000 and more',\n",
       " '000 appreciate',\n",
       " '000 appreciate it',\n",
       " '000 at',\n",
       " '000 at national',\n",
       " '000 audiophile',\n",
       " '000 audiophile music',\n",
       " '000 beliebers',\n",
       " '000 beliebers will',\n",
       " '000 bet',\n",
       " '000 bet user',\n",
       " '000 birds',\n",
       " '000 birds year',\n",
       " '000 black',\n",
       " '000 black market',\n",
       " '000 books',\n",
       " '000 books in',\n",
       " '000 books journey',\n",
       " '000 bring',\n",
       " '000 bring all',\n",
       " '000 but',\n",
       " '000 but ll',\n",
       " '000 by',\n",
       " '000 by this',\n",
       " '000 cd',\n",
       " '000 cd labels',\n",
       " '000 channels',\n",
       " '000 channels and',\n",
       " '000 characters',\n",
       " '000 chords',\n",
       " '000 chords for',\n",
       " '000 cold',\n",
       " '000 cold forged',\n",
       " '000 combinatio',\n",
       " '000 combinatio url',\n",
       " '000 cont',\n",
       " '000 cont url',\n",
       " '000 copies',\n",
       " '000 copies of',\n",
       " '000 copies sold',\n",
       " '000 could',\n",
       " '000 could you',\n",
       " '000 count',\n",
       " '000 count pound',\n",
       " '000 count stra',\n",
       " '000 count url',\n",
       " '000 ct',\n",
       " '000 ct bag',\n",
       " '000 ct feeder',\n",
       " '000 ct pack',\n",
       " '000 dect',\n",
       " '000 dect cordless',\n",
       " '000 designs',\n",
       " '000 designs url',\n",
       " '000 directioner',\n",
       " '000 directioner all',\n",
       " '000 dis',\n",
       " '000 distingu',\n",
       " '000 distingu url',\n",
       " '000 distinguishes',\n",
       " '000 distinguishes roads',\n",
       " '000 downloads',\n",
       " '000 downloads in',\n",
       " '000 each',\n",
       " '000 each case',\n",
       " '000 elegant',\n",
       " '000 elegant examples',\n",
       " '000 everyday',\n",
       " '000 everyday on',\n",
       " '000 fans',\n",
       " '000 fans thanks',\n",
       " '000 fine',\n",
       " '000 fine url',\n",
       " '000 finished',\n",
       " '000 finished hex',\n",
       " '000 followers',\n",
       " '000 followers every',\n",
       " '000 followers follow',\n",
       " '000 followers following',\n",
       " '000 followers followme',\n",
       " '000 followers for',\n",
       " '000 followers haha',\n",
       " '000 followers hard',\n",
       " '000 followers let',\n",
       " '000 followers lol',\n",
       " '000 followers on',\n",
       " '000 followers rt',\n",
       " '000 followers sooner',\n",
       " '000 followers that',\n",
       " '000 followers user',\n",
       " '000 followers we',\n",
       " '000 followers weloveyouashley',\n",
       " '000 followers xx',\n",
       " '000 follwers',\n",
       " '000 follwers and',\n",
       " '000 goes',\n",
       " '000 goes and',\n",
       " '000 goes to',\n",
       " '000 ha',\n",
       " '000 ha ha',\n",
       " '000 haha',\n",
       " '000 hex',\n",
       " '000 hex head',\n",
       " '000 hugs',\n",
       " '000 hugs is',\n",
       " '000 ideal',\n",
       " '000 ideal 30',\n",
       " '000 idevices',\n",
       " '000 idevices checked',\n",
       " '000 inden',\n",
       " '000 inden url',\n",
       " '000 is',\n",
       " '000 is to',\n",
       " '000 its',\n",
       " '000 its already',\n",
       " '000 jews',\n",
       " '000 jews that',\n",
       " '000 jobs',\n",
       " '000 jobs biz',\n",
       " '000 justsayin',\n",
       " '000 kg',\n",
       " '000 kg 497',\n",
       " '000 kg nuclear',\n",
       " '000 kg vet',\n",
       " '000 lb',\n",
       " '000 lb standard',\n",
       " '000 length',\n",
       " '000 length drill',\n",
       " '000 likes',\n",
       " '000 likes by',\n",
       " '000 little',\n",
       " '000 little monsters',\n",
       " '000 memories',\n",
       " '000 memphis',\n",
       " '000 memphis memphis',\n",
       " '000 merchants',\n",
       " '000 merchants way',\n",
       " '000 mg',\n",
       " '000 mg tabs',\n",
       " '000 mg vitamin',\n",
       " '000 miles',\n",
       " '000 miles begins',\n",
       " '000 miles today',\n",
       " '000 more',\n",
       " '000 more the',\n",
       " '000 multip',\n",
       " '000 multip url',\n",
       " '000 pcs',\n",
       " '000 pcs order',\n",
       " '000 people',\n",
       " '000 people donate',\n",
       " '000 people now',\n",
       " '000 people sure',\n",
       " '000 per',\n",
       " '000 per box',\n",
       " '000 per pack',\n",
       " '000 phill',\n",
       " '000 phill url',\n",
       " '000 phillips',\n",
       " '000 phillips binding',\n",
       " '000 phillips flat',\n",
       " '000 phillips pan',\n",
       " '000 ppl',\n",
       " '000 ppl during',\n",
       " '000 questions',\n",
       " '000 questions for',\n",
       " '000 riot',\n",
       " '000 riot protective',\n",
       " '000 rt',\n",
       " '000 rt user',\n",
       " '000 seats',\n",
       " '000 seats for',\n",
       " '000 slotte',\n",
       " '000 slotte url',\n",
       " '000 slotted',\n",
       " '000 slotted pan',\n",
       " '000 slotted round',\n",
       " '000 someone',\n",
       " '000 someone willing',\n",
       " '000 sperm',\n",
       " '000 sperm and',\n",
       " '000 steps',\n",
       " '000 steps today',\n",
       " '000 take',\n",
       " '000 take your',\n",
       " '000 th',\n",
       " '000 th follower',\n",
       " '000 th followr',\n",
       " '000 th tweeet',\n",
       " '000 th tweet',\n",
       " '000 that',\n",
       " '000 that you',\n",
       " '000 things',\n",
       " '000 things to',\n",
       " '000 think',\n",
       " '000 think the',\n",
       " '000 times',\n",
       " '000 times and',\n",
       " '000 times twitter',\n",
       " '000 to',\n",
       " '000 to user',\n",
       " '000 tonight',\n",
       " '000 tonight ll',\n",
       " '000 tweet',\n",
       " '000 tweet coming',\n",
       " '000 tweet goes',\n",
       " '000 tweet rt',\n",
       " '000 tweet so',\n",
       " '000 tweet soulmates',\n",
       " '000 tweet to',\n",
       " '000 tweets',\n",
       " '000 twitcam',\n",
       " '000 twitcam viewers',\n",
       " '000 url',\n",
       " '000 url internet',\n",
       " '000 user',\n",
       " '000 user melhor',\n",
       " '000 user that',\n",
       " '000 veiwers',\n",
       " '000 veiwers xx',\n",
       " '000 viewers',\n",
       " '000 viewers and',\n",
       " '000 viewers now',\n",
       " '000 viewers on',\n",
       " '000 viewers user',\n",
       " '000 viewers yet',\n",
       " '000 viewers you',\n",
       " '000 views',\n",
       " '000 views on',\n",
       " '000 views thank',\n",
       " '000 views the',\n",
       " '000 vitamin',\n",
       " '000 vitamin age',\n",
       " '000 ways',\n",
       " '000 ways to',\n",
       " '000 wet',\n",
       " '000 wet inlay',\n",
       " '000 white',\n",
       " '000 white sheets',\n",
       " '000 who',\n",
       " '000 who wants',\n",
       " '000 without',\n",
       " '000 without doing',\n",
       " '000 women',\n",
       " '000 women who',\n",
       " '000 word',\n",
       " '000 word essay',\n",
       " '000 word shor',\n",
       " '000 would',\n",
       " '000 would buy',\n",
       " '000 would help',\n",
       " '000 years',\n",
       " '000 years the',\n",
       " '000 years women',\n",
       " '000 yesterday',\n",
       " '000 yesterday stop',\n",
       " '000 you',\n",
       " '000 you ve',\n",
       " '0001 1ml',\n",
       " '0001 1ml pp',\n",
       " '0001 fits',\n",
       " '0001 fits life',\n",
       " '0001 high',\n",
       " '0001 high capacity',\n",
       " '0001 wh',\n",
       " '0001 wh gang',\n",
       " '0002 black',\n",
       " '0002 black leather',\n",
       " '0002 wh',\n",
       " '0002 wh gang',\n",
       " '00045 wireless',\n",
       " '00045 wireless intellimouse',\n",
       " '0005 22',\n",
       " '0005 22 logitech',\n",
       " '0005 condition',\n",
       " '0005 condition straightened',\n",
       " '0005 kgdis',\n",
       " '0005 kgdis url',\n",
       " '0006 shiny',\n",
       " '0006 shiny black',\n",
       " '0006 start',\n",
       " '0006 start getting',\n",
       " '0007 33',\n",
       " '0007 33 logitech',\n",
       " '0007 features',\n",
       " '0007 features brews',\n",
       " '0007301 stereo',\n",
       " '0007301 stereo hands',\n",
       " '00075descriptionas the',\n",
       " '00075descriptionas the url',\n",
       " '000idr can',\n",
       " '000idr can mention',\n",
       " '001 00',\n",
       " '001 00 router',\n",
       " '001 380443',\n",
       " '001 380443 001',\n",
       " '001 383966',\n",
       " '001 383966 001',\n",
       " '001 402',\n",
       " '001 402 580',\n",
       " '001 512mb',\n",
       " '001 512mb memory',\n",
       " '001 52',\n",
       " '001 52 m3',\n",
       " '001 bx',\n",
       " '001 bx 4024',\n",
       " '001 compatible',\n",
       " '001 compatible laptop',\n",
       " '001 condition',\n",
       " '001 condition straightened',\n",
       " '001 for',\n",
       " '001 for hp',\n",
       " '001 india',\n",
       " '001 india super',\n",
       " '001 laptop',\n",
       " '001 laptop battery',\n",
       " '001 large',\n",
       " '001 large black',\n",
       " '001 server',\n",
       " '001 server exam',\n",
       " '001 st',\n",
       " '001 st tweet',\n",
       " '001 tweet',\n",
       " '001 tweet goes',\n",
       " '001 url',\n",
       " '001127 00',\n",
       " '001127 00 compatible',\n",
       " '001152 00',\n",
       " '001152 00 compatible',\n",
       " '0017 single',\n",
       " '0017 single patterns',\n",
       " '002 11',\n",
       " '002 11 new',\n",
       " '002 13',\n",
       " '002 13 la',\n",
       " '002 ab2',\n",
       " '002 ab2 tripod',\n",
       " '002 compatible',\n",
       " '002 compatible laptop',\n",
       " '002 cyan',\n",
       " '002 cyan toner',\n",
       " '002 for',\n",
       " '002 for nearly',\n",
       " '002 le',\n",
       " '002 le rackmount',\n",
       " '002 not',\n",
       " '002 not bad',\n",
       " '002 premium',\n",
       " '002 premium toner',\n",
       " '0021 zip',\n",
       " '0021 zip notes',\n",
       " '0022 wh',\n",
       " '0022 wh recessed',\n",
       " '0028 312',\n",
       " '0028 312 url',\n",
       " '002ca 11',\n",
       " '002ca 11 4400mah',\n",
       " '002ca laptop',\n",
       " '002ca laptop battery',\n",
       " '002us 10',\n",
       " '002us 10 inch',\n",
       " '003 8678',\n",
       " '003 8678 80',\n",
       " '003 goblin',\n",
       " '003 goblin fan',\n",
       " '0032 41',\n",
       " '0032 41 url',\n",
       " '0034 02',\n",
       " '0034 02 created',\n",
       " '0035 stainless',\n",
       " '0035 stainless steel',\n",
       " '003b hdmi',\n",
       " '003b hdmi flat',\n",
       " '003mf mini',\n",
       " '003mf mini backlite',\n",
       " '003us 10',\n",
       " '003us 10 blue',\n",
       " '004 plastic',\n",
       " '004 plastic color',\n",
       " '004 vis',\n",
       " '004 vis racing',\n",
       " '0040 13',\n",
       " '0040 13 logitech',\n",
       " '004216 sold',\n",
       " '004216 sold as',\n",
       " '004a lithium',\n",
       " '004a lithium ion',\n",
       " '004a1b panasonic',\n",
       " '004a1b panasonic cga',\n",
       " '004mm vinyl',\n",
       " '004mm vinyl surface',\n",
       " '004r covers',\n",
       " '004r covers british',\n",
       " '004r irish',\n",
       " '004r irish sea',\n",
       " '004us black',\n",
       " '004us black url',\n",
       " '005 55',\n",
       " '005 55 459',\n",
       " '005 gallon',\n",
       " '005 gallon brand',\n",
       " '005 mandolin',\n",
       " '005 mandolin tm',\n",
       " '005 sailor',\n",
       " '005 sailor made',\n",
       " '005 shoulder',\n",
       " '005 shoulder screw',\n",
       " '005 steel',\n",
       " '005 steel arbor',\n",
       " '005 thick',\n",
       " '005 thick 18',\n",
       " '005 this',\n",
       " '005 this taurus',\n",
       " '0051 swivel',\n",
       " '0051 swivel fuel',\n",
       " '00540 antijam',\n",
       " '00540 antijam extra',\n",
       " '00540 manufacturer',\n",
       " '00540 manufacturer stanley',\n",
       " '006 thick',\n",
       " '006 thick 18',\n",
       " '006arm walkman',\n",
       " '006arm walkman contoured',\n",
       " '006f green',\n",
       " '006f green cables',\n",
       " '006us black',\n",
       " '006us black targus',\n",
       " '007 700',\n",
       " '007 classic',\n",
       " '007 classic edition',\n",
       " '007 goldeneye',\n",
       " '007 goldeneye 007',\n",
       " '007 helicopter',\n",
       " '007 helicopter controlled',\n",
       " '007 hyderabad',\n",
       " '007 hyderabad we',\n",
       " '007 moral',\n",
       " '007 moral compass',\n",
       " '007 thick',\n",
       " '007 thick 18',\n",
       " '0070 17',\n",
       " '0070 17 regal',\n",
       " '00706x1000 sold',\n",
       " '00706x1000 sold as',\n",
       " '007k2 diver',\n",
       " '007k2 diver automatic',\n",
       " '007s steering',\n",
       " '007s steering wheel',\n",
       " '008 thick',\n",
       " '008 thick pack',\n",
       " '0080 oz',\n",
       " '0080 oz pack',\n",
       " '008008 flex',\n",
       " '008008 flex grout',\n",
       " '0082 low',\n",
       " '0082 low range',\n",
       " '009 fluorosilicone',\n",
       " '009 fluorosilicone ring',\n",
       " '009 india',\n",
       " '009 india master',\n",
       " '009 xamonline',\n",
       " '009 xamonline teacher',\n",
       " '00am eat',\n",
       " '00am eat 04',\n",
       " '00h 43m',\n",
       " '00h 43m 16s',\n",
       " '00h 47m',\n",
       " '00h 47m 12s',\n",
       " '00h 56m',\n",
       " '00h 56m 34s',\n",
       " '00m 30s',\n",
       " '01 02',\n",
       " '01 02 03',\n",
       " '01 02 car',\n",
       " '01 0350',\n",
       " '01 0350 880',\n",
       " '01 05',\n",
       " '01 05 2009',\n",
       " '01 08',\n",
       " '01 08 26',\n",
       " '01 128mb',\n",
       " '01 128mb memory',\n",
       " '01 19',\n",
       " '01 19 20',\n",
       " '01 2007',\n",
       " '01 2007 url',\n",
       " '01 2011',\n",
       " '01 2011 run',\n",
       " '01 2012',\n",
       " '01 2012 15',\n",
       " '01 3012',\n",
       " '01 3012 176',\n",
       " '01 3404',\n",
       " '01 3404 241',\n",
       " '01 3404 270',\n",
       " '01 3404 321',\n",
       " '01 36',\n",
       " '01 36 and',\n",
       " '01 38',\n",
       " '01 38 actionpacker',\n",
       " '01 6664',\n",
       " '01 6664 01',\n",
       " '01 acura',\n",
       " '01 acura integra',\n",
       " '01 adaptor',\n",
       " '01 adaptor cga',\n",
       " '01 am',\n",
       " '01 can',\n",
       " '01 can work',\n",
       " '01 cherokee',\n",
       " '01 cherokee jeep',\n",
       " '01 cisco',\n",
       " '01 cisco 376w',\n",
       " '01 clayton',\n",
       " '01 clayton tank',\n",
       " '01 company',\n",
       " '01 company ground',\n",
       " '01 cs50',\n",
       " '01 cs50 hl10',\n",
       " '01 david',\n",
       " '01 david divine',\n",
       " '01 eva',\n",
       " '01 eva blue',\n",
       " '01 keyboard',\n",
       " '01 keyboard wedge',\n",
       " '01 make',\n",
       " '01 make your',\n",
       " '01 maximum',\n",
       " '01 maximum solid',\n",
       " '01 multi',\n",
       " '01 multi color',\n",
       " '01 on',\n",
       " '01 on sunday',\n",
       " '01 oz',\n",
       " '01 oz health',\n",
       " '01 pc35',\n",
       " '01 pc35 ph35',\n",
       " '01 purple',\n",
       " '01 purple figure',\n",
       " '01 revenue',\n",
       " '01 revenue of',\n",
       " '01 signature',\n",
       " '01 signature stick',\n",
       " '01 since',\n",
       " '01 since its',\n",
       " '01 test',\n",
       " '01 test prepgets',\n",
       " '01 test preps',\n",
       " '01 tonight',\n",
       " '01 tsst',\n",
       " '01 tsst features',\n",
       " '01 url',\n",
       " '01 url for',\n",
       " '01 wide',\n",
       " '01 wide complete',\n",
       " '01 with',\n",
       " '01 with series',\n",
       " '01 wtf',\n",
       " '010 0070',\n",
       " '010 0070 17',\n",
       " '010 1014',\n",
       " '010 1014 00',\n",
       " '010 1026',\n",
       " '010 1026 00',\n",
       " '010 1032',\n",
       " '010 1032 00',\n",
       " '010 1075',\n",
       " '010 1075 00',\n",
       " '010 thick',\n",
       " '010 thick pack',\n",
       " '010 url',\n",
       " '01010323 00',\n",
       " '01010323 00 customers',\n",
       " '0102 312',\n",
       " '0102 312 url',\n",
       " '011 action',\n",
       " '011 action licensed',\n",
       " '0111p cell',\n",
       " '0111p cell 4400mah',\n",
       " '0113 item',\n",
       " '0113 item 11',\n",
       " '0113 made',\n",
       " '0113 made of',\n",
       " '012 10',\n",
       " '012 10 protect',\n",
       " '012 sardinia',\n",
       " '012 sardinia south',\n",
       " '012 steps',\n",
       " '012 steps and',\n",
       " '012 toshiba',\n",
       " '012 toshiba battery',\n",
       " '0121 notebook',\n",
       " '0121 notebook laptop',\n",
       " '0125 g10',\n",
       " '0125 g10 handle',\n",
       " '0125 url',\n",
       " '01291 liquid',\n",
       " '01291 liquid rust',\n",
       " '012l compatible',\n",
       " '012l compatible laptop',\n",
       " '012r covers',\n",
       " '012r covers from',\n",
       " '012r italy',\n",
       " '012r italy west',\n",
       " '0130be wild',\n",
       " '0130be wild for',\n",
       " '0131 hd',\n",
       " '0131 hd rubberized',\n",
       " '0137 seethru',\n",
       " '0137 seethru satin',\n",
       " '0139 item',\n",
       " '0139 item 11',\n",
       " '0139 made',\n",
       " '0139 made of',\n",
       " '0139 women',\n",
       " '0139 women white',\n",
       " '014 gy',\n",
       " '014 gy snagless',\n",
       " '014 toy',\n",
       " '014 toy pieces',\n",
       " '014 wall',\n",
       " '014 wall 12',\n",
       " '014 wall 36',\n",
       " '0148 url',\n",
       " '0149 single',\n",
       " '0149 single patterns',\n",
       " '014bl augmented',\n",
       " '014bl augmented cat',\n",
       " '015 afghanistan',\n",
       " '015 afghanistan the',\n",
       " '015 thick',\n",
       " '015 thick pack',\n",
       " '015 wall',\n",
       " '015 wall 36',\n",
       " '015 wide',\n",
       " '015 wide complete',\n",
       " '01524 dvd',\n",
       " '01524 dvd storage',\n",
       " '0153 access',\n",
       " '0153 access 2213508',\n",
       " '016 178',\n",
       " '016 178 antiquity',\n",
       " '016 1886',\n",
       " '016 1886 00',\n",
       " '01684 aquaseal',\n",
       " '01684 aquaseal reusable',\n",
       " '0178 xpower',\n",
       " '0178 xpower 175',\n",
       " '019 buna',\n",
       " '019 buna quad',\n",
       " '019 chance',\n",
       " '019 chance that',\n",
       " '01910 01910',\n",
       " '01910 01910 model',\n",
       " '01910 model',\n",
       " '01910 model code',\n",
       " '01910 this',\n",
       " '01910 this item',\n",
       " '0196 1292',\n",
       " '0196 1292 vol',\n",
       " '01966 hp',\n",
       " '01966 hp q5949x',\n",
       " '019us black',\n",
       " '019us black with',\n",
       " '01a vertical',\n",
       " '01a vertical pouch',\n",
       " '01h 00m',\n",
       " '01h 00m 30s',\n",
       " '01l item',\n",
       " '01l item g42703',\n",
       " '01us the',\n",
       " '01us the targus',\n",
       " '02 01',\n",
       " '02 01 2011',\n",
       " '02 02',\n",
       " '02 02 amn',\n",
       " '02 03',\n",
       " '02 03 04',\n",
       " '02 05',\n",
       " '02 05 2012',\n",
       " '02 06',\n",
       " '02 06 cold',\n",
       " '02 06 intake',\n",
       " '02 06 mini',\n",
       " '02 06 subaru',\n",
       " '02 07',\n",
       " '02 07 dodge',\n",
       " '02 12',\n",
       " '02 22',\n",
       " '02 22 117',\n",
       " '02 26',\n",
       " '02 26 2008',\n",
       " '02 airfloss',\n",
       " '02 airfloss health',\n",
       " '02 amn',\n",
       " '02 amn it',\n",
       " '02 bo',\n",
       " '02 bo url',\n",
       " '02 car',\n",
       " '02 car radio',\n",
       " '02 continuum',\n",
       " '02 continuum stanley',\n",
       " '02 created',\n",
       " '02 created in',\n",
       " '02 ct',\n",
       " '02 ct si1',\n",
       " '02 extreme',\n",
       " '02 extreme dimensions',\n",
       " '02 followers',\n",
       " '02 investing',\n",
       " '02 investing over',\n",
       " '02 is',\n",
       " '02 is an',\n",
       " '02 kg',\n",
       " '02 kg med',\n",
       " '02 km',\n",
       " '02 km hr',\n",
       " '02 minisync',\n",
       " '02 minisync mobile',\n",
       " '02 pyramid',\n",
       " '02 pyramid composter',\n",
       " '02 qms',\n",
       " '02 qms cyan',\n",
       " '02 radeon',\n",
       " '02 radeon 9800',\n",
       " '02 rt',\n",
       " '02 rt user',\n",
       " '02 share',\n",
       " '02 share to',\n",
       " '02 the',\n",
       " '02 the air',\n",
       " '02 woman',\n",
       " '02 woman is',\n",
       " '02 your',\n",
       " '02 your factory',\n",
       " '02 z3',\n",
       " '02 z3 line',\n",
       " '020 diameter',\n",
       " '020 diameter 60',\n",
       " '020 pack',\n",
       " '020 pack of',\n",
       " '0201 20',\n",
       " '0201 20 200ppm',\n",
       " '0201 omd',\n",
       " '0201 omd optical',\n",
       " '02068 manufacturer',\n",
       " '02068 manufacturer kimbe',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1545439)\t0.6137253465901165\n",
      "  (0, 1545391)\t0.5986770157179925\n",
      "  (0, 1327337)\t0.5147106272497588\n",
      "  (1, 1638264)\t0.19600057161081771\n",
      "  (1, 1638263)\t0.19600057161081771\n",
      "  (1, 1287807)\t0.19123011097439563\n",
      "  (1, 1287806)\t0.19123011097439563\n",
      "  (1, 1280103)\t0.16723671439822707\n",
      "  (1, 1279824)\t0.17778293770295842\n",
      "  (1, 1279823)\t0.17603580696138937\n",
      "  (1, 1274540)\t0.17973606370225492\n",
      "  (1, 1274482)\t0.17603580696138937\n",
      "  (1, 1274479)\t0.2722457367285321\n",
      "  (1, 1076072)\t0.19600057161081771\n",
      "  (1, 1076070)\t0.184506524338677\n",
      "  (1, 1054045)\t0.18752985423353008\n",
      "  (1, 1053776)\t0.09519331049675611\n",
      "  (1, 997151)\t0.18752985423353008\n",
      "  (1, 997150)\t0.18752985423353008\n",
      "  (1, 983866)\t0.19600057161081771\n",
      "  (1, 983865)\t0.19600057161081771\n",
      "  (1, 312273)\t0.19123011097439563\n",
      "  (1, 312269)\t0.18195033533487007\n",
      "  (1, 26433)\t0.18752985423353008\n",
      "  (1, 26431)\t0.184506524338677\n",
      "  :\t:\n",
      "  (150000, 1304054)\t0.18729098034516042\n",
      "  (150000, 1304049)\t0.16263438529883914\n",
      "  (150000, 1225856)\t0.18729098034516042\n",
      "  (150000, 1225850)\t0.1680986468201588\n",
      "  (150000, 1198040)\t0.18729098034516042\n",
      "  (150000, 1198039)\t0.18729098034516042\n",
      "  (150000, 1136822)\t0.18729098034516042\n",
      "  (150000, 1136815)\t0.16263438529883914\n",
      "  (150000, 992730)\t0.1107336689740371\n",
      "  (150000, 794042)\t0.18107925331996816\n",
      "  (150000, 794036)\t0.1564226582736469\n",
      "  (150000, 773034)\t0.18729098034516042\n",
      "  (150000, 773001)\t0.12880361273859986\n",
      "  (150000, 601114)\t0.18107925331996816\n",
      "  (150000, 601110)\t0.17046023583160905\n",
      "  (150000, 553988)\t0.1564226582736469\n",
      "  (150000, 553975)\t0.11628691431107935\n",
      "  (150000, 542933)\t0.18729098034516042\n",
      "  (150000, 542924)\t0.14530130057275709\n",
      "  (150000, 462652)\t0.18729098034516042\n",
      "  (150000, 462649)\t0.17667196285680128\n",
      "  (150000, 213678)\t0.18729098034516042\n",
      "  (150000, 213677)\t0.18729098034516042\n",
      "  (150000, 197702)\t0.17046023583160905\n",
      "  (150000, 197667)\t0.12562257686672232\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(count_vect.transform([\"hoho\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 459540)\t1\n",
      "  (0, 806079)\t1\n",
      "  (0, 806085)\t1\n",
      "  (0, 866897)\t1\n",
      "  (0, 867185)\t1\n",
      "  (0, 867221)\t1\n",
      "  (0, 918601)\t1\n",
      "  (0, 1019327)\t1\n",
      "  (0, 1019438)\t1\n",
      "  (0, 1238534)\t1\n",
      "  (0, 1238538)\t1\n",
      "  (0, 1310769)\t1\n",
      "  (0, 1621222)\t1\n",
      "  (0, 1647723)\t1\n",
      "  (0, 1647730)\t1\n",
      "  (0, 1693947)\t1\n",
      "  (0, 1693986)\t1\n",
      "  (1, 141406)\t1\n",
      "  (1, 141549)\t1\n",
      "  (1, 696087)\t1\n",
      "  (1, 718036)\t1\n",
      "  (1, 718078)\t1\n",
      "  (1, 779081)\t1\n",
      "  (1, 779086)\t1\n",
      "  (1, 1137141)\t1\n",
      "  :\t:\n",
      "  (49999, 1245917)\t1\n",
      "  (49999, 1458157)\t1\n",
      "  (49999, 1458169)\t1\n",
      "  (49999, 1586563)\t1\n",
      "  (49999, 1586631)\t1\n",
      "  (49999, 1609085)\t1\n",
      "  (50000, 112131)\t1\n",
      "  (50000, 121541)\t1\n",
      "  (50000, 179951)\t1\n",
      "  (50000, 281115)\t1\n",
      "  (50000, 345772)\t1\n",
      "  (50000, 348176)\t1\n",
      "  (50000, 945605)\t1\n",
      "  (50000, 988008)\t1\n",
      "  (50000, 1043736)\t1\n",
      "  (50000, 1332236)\t1\n",
      "  (50000, 1379420)\t1\n",
      "  (50000, 1456357)\t1\n",
      "  (50000, 1456358)\t1\n",
      "  (50000, 1632858)\t1\n",
      "  (50000, 1633224)\t1\n",
      "  (50000, 1634772)\t1\n",
      "  (50000, 1634789)\t1\n",
      "  (50000, 1676953)\t1\n",
      "  (50000, 1676956)\t1\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model's accuracy is 0.7927041459170816\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(count_vect.transform(X_test))\n",
    "print(f'Our model\\'s accuracy is {metrics.accuracy_score(y_test, predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        sea doo pro sea scooter ( sports with the po.....\n",
       "2        <user> shucks well i work all week so now i .....\n",
       "3        i cant stay away from bug thats my baby\\nName:...\n",
       "4        <user> no ma'am ! ! ! lol im perfectly fine .....\n",
       "5        whenever i fall asleep watching the tv , i a.....\n",
       "                               ...                        \n",
       "9996     had a nice time w / my friend lastnite\\nName: ...\n",
       "9997     <user> no it's not ! please stop !\\nName: 9997...\n",
       "9998     not without my daughter ( dvd two-time os...\\n...\n",
       "9999     <user> have fun in class sweetcheeks\\nName: 99...\n",
       "10000    making a r . e . a . l . difference . ( ...\\nN...\n",
       "Length: 10000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unknown = pd.read_csv('data/test_data.txt', sep=\"\\n\", header=None)\n",
    "df_unknown.columns = [\"tweet\"]\n",
    "df_unknown.index += 1 \n",
    "df_unknown = df_unknown.apply(lambda x : str(x).split(',', maxsplit=1)[1],axis=1)\n",
    "df_unknown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#y_test = clf.predict(count_vect.transform(x_unknown))\n",
    "df_unknown = clf.predict(count_vect.transform(df_unknown.values))\n",
    "df_unknown[df_unknown == 0] = -1 #replace 0 to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, ..., -1,  1,  1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = list(zip([x for x in range(1,len(df_unknown)+1)],df_unknown))\n",
    "create_csv_submission([x for x in range(1,len(df_unknown)+1)],df_unknown,\"output_dummy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nb_word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-768da17a58ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_word\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglove_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborder_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nb_word' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers.embeddings import Embedding\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "# Fisrt model\n",
    "np.random.seed(1)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Embedding(nb_word+1, 200, input_length=X_sequences.shape[1], weights=[glove_matrix]))\n",
    "model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
